\chapter{AI Component Design}
\label{ch:ai-component-design}

% 5.1
\section{Business Context and AI Integration}
\label{sec:business-context}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/ssl-workflow}
    \caption{Self-supervised learning for semantic feature extraction from EEG signals.}
    \label{fig:ssl-workflow}
\end{figure}
\noindent

\vspace{1em}
\noindent\textbf{Diagram Explanation:}
The system is designed as an experimental EEG research platform integrating signal visualization, dataset inspection, and machine learning experimentation into a unified workflow.
The frontend interface allows users to explore EEG signals, construct datasets, and execute AI models, while the backend handles preprocessing, model execution, and evaluation.

The workflow proceeds as:

signal inspection → dataset verification → model training → evaluation → comparison

This ensures that machine learning results are directly connected to verified signal characteristics rather than blindly training on raw data.
\pagebreak

\vspace{1em}
\noindent\textbf{Why is AI suitable for this problem?}

EEG analysis involves high-dimensional temporal signals with complex spatial relationships across electrodes. Manual feature engineering is difficult because:

\begin{itemize}
    \item patterns vary across subjects
    \item noise and artifacts are common
    \item signal distributions change across recording sessions
\end{itemize}
Machine learning models can learn latent representations that capture discriminative neural patterns more effectively than handcrafted features.

\vspace{0.5em}
\noindent\textbf{Is the problem large, complex, or always changing?}

Yes.


EEG data presents three major challenges:
\begin{itemize}
    \item Large — continuous multi-channel time series
    \item Complex — spatial-temporal correlations
    \item Non-stationary — signals differ between subjects and sessions
\end{itemize}
Because of this variability, deterministic rule-based systems are unsuitable.

\vspace{0.5em}
\noindent\textbf{Can we accept an answer that’s not 100\% perfect?}

Yes. This is a research system.

\vspace{0.5em}

The system is intended for research experimentation rather than safety-critical decision making.
Model predictions are used as analytical indicators, not medical diagnoses.
Therefore probabilistic predictions with measurable accuracy are acceptable.

%5.2
\section{Goal Hierarchy}
\label{sec:goal-hierarchy}

\noindent\textbf{Organizational Goal:} Enable efficient experimentation in EEG machine learning research

\vspace{0.5em}
\noindent\textbf{System Goal:} Provide an interactive platform that links signal inspection with machine learning experimentation

\vspace{0.5em}
\noindent\textbf{User Goal:} Explore EEG signals, construct datasets, train models, and compare results without manual scripting

\vspace{0.5em}
\noindent\textbf{AI Model Goal:} Learn representations that generalize across subjects and improve classification performance

\vspace{1em}
\noindent\textbf{Success Metrics:}
\begin{itemize}
    \item classification accuracy improvement over baseline
    \item consistent performance on unseen subjects
    \item reduced experiment setup time
    \item reproducible experiment workflow
\end{itemize}

%5.3
\section{Task Requirements Analysis Using AI Canvas}
\label{sec:ai-canvas}

\subsection{AI Task Requirements}
\label{subsec:ai-task-requirements}
\begin{itemize}[leftmargin=3.5em]
    \item \textbf{Requirements (REQ):} Learn discriminative EEG representations for motor-imagery classification using standardized datasets.
    \item \textbf{Specifications (SPEC):} Evaluate whether learned representations improve classification accuracy and generalization compared to baseline approaches.
    \item \textbf{Environment (ENV):} Evaluated on multi-subject EEG datasets with different recording conditions. (e.g., noise, subject variation).
\end{itemize}

\subsection{AI Canvas Summary}
\label{subsec:ai-canvas-summary}
\begin{itemize}[leftmargin=3.5em]
    \item \textbf{Input:} Preprocessed EEG segments
    \item \textbf{Output:} Predicted motor-imagery class labels
    \item \textbf{Success Criteria:} Model performs better than random guessing and generalizes to unseen subjects. (Ideally $>$80\% accuracy)
\end{itemize}

\subsection{Innovation}
\label{subsec:innovation}
The system integrates visualization-driven dataset validation with model training inside a single interactive interface, reducing mismatch between inspected signals and training data.

\pagebreak
%5.4
\section{User Experience Design with AI}
\label{sec:ux-ai}

The platform follows a research-oriented workflow where users first inspect signals before executing machine learning models.
To support this process, the interface uses a \textbf{mode-action} structure.

\vspace{1em}
\noindent\textbf{Interface Overview:}
The interface contains four primary operational modes:

\begin{itemize}[leftmargin=3.5em]
    \item \textbf{Plot Mode:} — detailed single-view signal inspection
    \item \textbf{Grid Plot Mode:} — comparative multi-condition visualization
    \item \textbf{Data Mode:} — structured data inspection and preparation
    \item \textbf{AI Mode:} — machine learning experimentation
\end{itemize}

Each mode exposes only relevant actions.

\vspace{2em}
\noindent\textbf{Visualization and Inspection Modes}

\subsection{Plot Mode}

Provides detailed EEG inspection including sensor layout, time-domain plots, frequency plots, epoch plots, evoked responses, and SNR analysis.

Available actions include:
\begin{itemize}
    \item sensor layout visualization
    \item time-domain signal plots
    \item frequency-domain plots
    \item epoch visualization
    \item evoked response plots
    \item evoked topography plots
    \item SNR spectrum analysis
\end{itemize}

\subsection{Grid Plot Mode}

Allows comparison across conditions using PSD, SNR, and evoked grids.

Available actions include:
\begin{itemize}
    \item PSD Grid
    \item SNR Grid
    \item Evoked Grid
\end{itemize}

\subsection{Data Mode}

Displays structured EEG data tables to confirm dataset composition.

Available actions include:
\begin{itemize}
    \item EEG sample tables
    \item epoch tables
    \item metadata
\end{itemize}

\subsection{AI Interaction Mode}

AI Mode enables machine learning experimentation using the prepared EEG data.

Available actions include:

\begin{itemize}
    \item Training
    \item Prediction
    \item Evaluation
    \item Model Comparison
\end{itemize}

\vspace{1em}
\noindent\textbf{System Behavior:}
Upon user interaction, the backend automatically executes preprocessing, training, evaluation, and result generation.
Logs, graphs, and final metrics are dynamically updated and available for export.

\vspace{1em}
\noindent\textbf{Feedback Loop:}
inspect → adjust → train → evaluate → compare → refine

Researchers can rapidly modify dataset selections and rerun experiments without rewriting scripts or managing computing environments. This significantly shortens the experimental cycle compared to notebook-based pipelines.

\noindent\textbf{Interface Screenshots:}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/ui/EEGUI}
    \caption{React Notebook Interface – Model visualization and execution}
    \label{fig:ui_react_notebook}
\end{figure}

%Evoked & Epoch Plots
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/epochs.png}
    \caption{Epoch visualization}
    \label{fig:plot_epochs}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/evoked.png}
    \caption{Evoked response}
    \label{fig:plot_evoked}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/evoked_grid.png}
    \caption{Evoked grid view}
    \label{fig:plot_evoked_grid}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/evoked_joint.png}
    \caption{Evoked joint plot}
    \label{fig:plot_evoked_joint}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/evoked_topo.png}
    \caption{Evoked topomap}
    \label{fig:plot_evoked_topo}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/evoked_per_condition.png}
    \caption{Evoked per condition}
    \label{fig:plot_evoked_per_condition}
\end{figure}

%Frequency & Spectral Analysis
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/frequency.png}
    \caption{Frequency spectrum}
    \label{fig:plot_frequency}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/psd_grid.png}
    \caption{Power spectral density grid}
    \label{fig:plot_psd_grid}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/snr_spectrum.png}
    \caption{Signal-to-noise ratio spectrum}
    \label{fig:plot_snr_spectrum}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/snr_grid.png}
    \caption{Signal-to-noise ratio grid}
    \label{fig:plot_snr_grid}
\end{figure}

%Sensor & Time Domain
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/sensor.png}
    \caption{Sensor layout}
    \label{fig:plot_sensor}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/plot/time_domain.png}
    \caption{Time-domain signal}
    \label{fig:plot_time_domain}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/ui/train_model}
    \caption{Training Interface – Dataset selection, SSL configuration, and training log}
    \label{fig:ui_train_model}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/ui/predict_model}
    \caption{Prediction Interface – Uploading input data and viewing output class with confidence}
    \label{fig:ui_predict_model}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/ui/evaluate_model}
    \caption{Evaluation Interface – Upload trained model and view performance metrics and curve}
    \label{fig:ui_evaluate_model}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/ui/compare_model}
    \caption{Comparison Interface – Visual comparison between SSL and Supervised models}
    \label{fig:ui_compare_mode}
\end{figure}

\FloatBarrier

%5.5
\section{Deployment Strategy}
\label{sec:deployment-strategy}

\subsection{Deployment Plan}
\label{subsec:deployment-plan}
The AI component is deployed in a research environment using both local execution and cloud notebooks.

The system consists of:

Frontend — interactive research interface
Backend — REST API service
Model — EEG classification network

Technologies used:

\begin{itemize}
    \item React — interactive frontend framework
    \item FastAPI — model service endpoints
    \item TensorFlow — neural network execution
    \item scientific Python libraries — preprocessing and evaluation
\end{itemize}



The frontend web system replaces manual notebook execution and allows controlled interaction with the EEG pipeline,
and the backend exposes endpoints for training, prediction, and evaluation, allowing modular integration and testing.

The core model used in our system is based on \textbf{MixNet-BCI}, an open-source EEG classification framework developed by VISTEC. This model is integrated into our workflow for signal preprocessing, feature extraction, and classification of motor imagery tasks.

\subsection{Proof of Concept}
\label{subsec:proof-of-concept}
The model pipeline was validated using benchmark EEG datasets under two conditions:

\begin{itemize}
    \item \textbf{Subject-Dependent Setting:} Model is trained and tested on individual subjects.
    \item \textbf{Subject-Independent Setting:} Model is trained on a group of subjects and tested on unseen individuals.
\end{itemize}

The system successfully supports end-to-end workflow:

visualization → dataset selection → training → inference → evaluation

Results can be accessed both through the interface and API endpoints.

%5.6
\section{Reflection and Future Development}
\label{sec:reflection}


\subsection*{Lessons Learned}
\begin{itemize}[leftmargin=3.5em]
    \item SSL can extract high-quality embeddings from unlabeled EEG data that generalize to MI classification tasks.
    \item Multi-paradigm training (e.g., SSVEP + ERP) provides richer features than MI alone.
    \item Integrated workflows reduce experimentation overhead
\end{itemize}


\subsection*{Challenges}
\begin{itemize}[leftmargin=3.5em]
    \item subject variability affects generalization
    \item interpreting learned representations remains difficult
    \item noisy EEG signals impact performance
\end{itemize}

\subsection*{Future Work}
\begin{itemize}[leftmargin=3.5em]
    \item transformer-based temporal modeling
    \item real-time prediction interface
    \item automated hyperparameter search
    \item live experiment integration
\end{itemize}
