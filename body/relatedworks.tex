\chapter{Literature Review and Related Work}
\label{ch:relatedworks}

This chapter presents related research efforts and existing solutions addressing the classification of EEG-based Motor Imagery (MI) signals. The review includes a technical comparison of frameworks using supervised and self-supervised learning (SSL), followed by a literature analysis of state-of-the-art systems. These insights help position our work within the current research landscape and identify key gaps we aim to address.

\section{Competitor Analysis}
\label{sec:competitor-analysis}

To evaluate current EEG MI classification frameworks, we analyzed their model architecture, feature extraction approaches, performance, learning strategies, and support for multi-dataset generalization. The results are summarized in Table~\ref{tab:competitor-comparison}.

\begin{table}[H]
    \centering
    \caption{Technical Comparison of EEG MI Classification Frameworks}
    \label{tab:competitor-comparison}
    \small
    \begin{tabularx}{\textwidth}{|p{2cm}|p{2.2cm}|p{2.2cm}|p{1.7cm}|p{2cm}|p{2cm}|}
        \hline
        \textbf{Framework} & \textbf{Model Architecture} & \textbf{Feature Extraction} & \textbf{Accuracy} & \textbf{Learning Type} & \textbf{Multi-Dataset Support} \\
        \hline
        MixNet (2024) & Multi-task Autoencoder with FBCSP and Triplet Loss & Filter Bank CSP, latent space embeddings & 85.4\% (BCIC2a) & Supervised + Metric Learning & Partial (manual alignment) \\
        \hline
        TRIPNet (2024) & Triple-path CNN (spectral, spatial, temporal) + Statistician Module & Pretext-task-driven SSL (band prediction, spatial noise, temporal trend) & 88.6\% (OpenBMI) & Self-Supervised & Full (4 paradigms) \\
        \hline
        EEG-SSL (2024) & Modular BIDS-compatible SSL framework & Raw EEG + transformations (crop, mask, time-shift) & 80.1\% (Resting-state) & Self-Supervised & Full (BIDS format) \\
        \hline
    \end{tabularx}
\end{table}
\noindent
\textbf{Observations:}
\begin{itemize}
    \item \textbf{TRIPNet} delivers the highest reported accuracy and excels in subject-independent tasks through tailored pretext tasks.
    \item \textbf{MixNet} balances classical signal processing with deep learning but is limited by manual preprocessing across datasets.
    \item \textbf{EEG-SSL} offers excellent scalability and dataset handling via BIDS format, with slightly lower classification accuracy.
    \item \textbf{EEGNet}, while lightweight and widely used as a baseline, lacks generalization and modern learning strategies.
\end{itemize}

\noindent
Our proposed framework aims to combine the strengths of these systems—accurate feature extraction, dataset scalability, and robustness—into a self-supervised model that is also user-accessible through a visual interface.

\section{Literature Review}
\label{sec:literature-review}

\textbf{MixNet (Autthasan et al., 2024):}
MixNet (Autthasan et al., 2024) is a novel framework that integrates Filter Bank Common Spatial Patterns (FBCSP) with a deep metric learning structure, combining autoencoders and triplet loss to optimize EEG-based Motor Imagery (MI) classification. This approach is designed to perform well in both subject-dependent and subject-independent scenarios, addressing challenges related to subject-specific learning and multi-task learning. By utilizing spectral-spatial signal integration, adaptive gradient blending, and multi-task autoencoders, MixNet demonstrates improved classification performance compared to previous models such as MIN2Net, EEGNet, and DeepConvNet.

However, a limitation of MixNet is its reliance on manual dataset alignment, which hinders its scalability and practical use in real-world applications. The lack of automated preprocessing tools further limits its usability, as it requires careful manual intervention for dataset preparation. Despite these challenges, MixNet stands out for its efficiency, accuracy, and potential for deployment in low-density EEG systems, making it suitable for wearable devices and mobile healthcare applications.

While MixNet outperforms state-of-the-art methods in terms of F1-score and computational efficiency, especially in the low-density EEG dataset BCIC IV2b, the need for manual preprocessing underscores the need for further development in automated tools to streamline its application in practical scenarios.

\vspace{0.5em}
\newpage
\textbf{TRIPNet (Ko et al., 2024):}
TRIPNet (Ko et al., 2024) introduces a deep learning framework designed specifically for EEG signals, utilizing a three-pathway architecture that captures spectral, spatial, and temporal characteristics of the data. The model leverages custom self-supervised tasks for pretraining, enabling it to learn meaningful EEG representations without the need for costly human-centered annotations. These self-supervision strategies are carefully crafted to be neurophysiologically plausible, ensuring that the network can learn EEG features effectively while remaining consistent with neurobiological principles.

A key innovation in TRIPNet is the integration of the statistician module, which adaptively normalizes the input features based on their statistics. This module plays a crucial role in controlling the variability of the EEG signals, enhancing the stability and performance of the model across different conditions. The inclusion of this module also ensures that the framework is well-suited to generalize across various EEG paradigms, making it applicable to a wide range of EEG-based applications.

Through extensive empirical experiments, the authors validate the framework's effectiveness, highlighting the individual contributions of each component, such as the self-supervision methods and the statistician module. These results demonstrate that TRIPNet excels in representing EEG signals by efficiently managing the signal variability and capturing neurophysiologically meaningful patterns, especially through its stopped band prediction pretext task. This task involves band-stop filtering of predefined EEG frequency ranges ($\delta, \theta, \alpha, \beta, \gamma$ bands) to represent neural oscillations. However, it should be noted that the consistent use of predefined frequency ranges may complicate spectral representation learning due to subject-specific variations and environmental influences.

Looking ahead, the authors suggest that future research could explore hyperspectral synthesis and augmentation of EEG samples in a more rigorous image-processing manner, which could lead to novel pretext tasks for self-supervised learning. This would potentially eliminate the reliance on prior knowledge of frequency ranges and further enhance the flexibility of the model in diverse environments.

In conclusion, TRIPNet offers a significant step forward in EEG representation, demonstrating its ability to provide reliable decision-making with zero-calibration data and a user-friendly system. Despite its promising results, there is still room for improvement, particularly in exploring new pretext tasks for self-supervision.

\vspace{0.5em}
\newpage
\textbf{EEG-SSL (Truong et al., 2024):}
The proposed Self-Supervised Learning (SSL) framework effectively addresses the challenges of large-scale EEG analysis by leveraging BIDS-formatted datasets. This framework facilitates efficient data preprocessing, segmentation, and encoding, overcoming the variability of channel configurations across different datasets. By incorporating self-supervised transformations, such as masking and time-shifting, the framework enables robust representation learning without requiring labeled data. This approach demonstrated its potential through experiments like the Relative Positioning (RP) task, where the model successfully learned meaningful representations, with training loss curves validating its learning capability.

A key feature of the framework is its modularity and flexibility, allowing researchers to customize experiments based on their needs. It accepts various BIDS-formatted EEG datasets, enabling it to process datasets of different sizes, modalities, and configurations. The SSL tasks, such as temporal contrastive learning or masked predictive coding, and model architectures (e.g., CNNs, Transformers) are fully customizable to suit specific research objectives. Despite this flexibility, the framework maintains fixed components, such as the hierarchical parsing of BIDS datasets, standardized preprocessing pipelines, and a core training loop. This balance ensures reproducibility and scalability for large-scale experiments, supporting rapid experimentation and big data workflows.

While the SSL framework is suitable for a variety of EEG paradigms, it is better optimized for tasks like resting-state EEG rather than task-specific classification (e.g., Motor Imagery (MI)). The framework’s design also addresses the challenge of channel harmonization, where inter-channel relationships are learned directly from raw data at the model level, providing flexibility for different EEG channel configurations.

In terms of future directions, the framework shows promise for downstream tasks, such as cognitive state classification, anomaly detection, and clinical diagnosis. However, further research is needed to compare its performance against supervised models trained on labeled data. The key advantage of SSL lies in its ability to leverage vast amounts of unlabeled EEG data, which is typically unavailable for labeled data tasks. This could lead to better generalization, especially in scenarios with limited labeled data or high inter-subject variability. Future studies should benchmark this approach to quantify the impact of pretraining with SSL on downstream task performance.

Overall, this framework’s ability to process large-scale EEG data with minimal human annotation, while providing a flexible and customizable architecture, positions it as a strong foundation for future neuroinformatics research.

\vspace{0.5em}
\newpage
\textbf{Research Gap:}
While previous works such as MixNet, TRIPNet, and the Self-Supervised Learning (SSL) framework contribute strong models and scalable frameworks for EEG analysis, no existing approach fully integrates multi-dataset SSL training, efficient Motor Imagery (MI) task handling, and user accessibility within a single system. MixNet excels in subject-independent MI classification but is limited by manual dataset alignment and preprocessing, which hinders scalability and usability in real-world scenarios. Similarly, TRIPNet utilizes a robust three-pathway architecture for spectral, spatial, and temporal features but is more suited for general EEG applications rather than task-specific classifications like MI. The SSL framework, while highly flexible and modular, is optimized for resting-state EEG tasks and lacks direct support for task-specific classifications like MI, making it less suitable for time-sensitive applications like motor imagery.

This research gap forms the foundation of our proposed work, which aims to develop a unified system that supports multi-dataset SSL training, efficient MI task handling, and user accessibility. Our system will integrate the strengths of these previous works while addressing their limitations, offering a more comprehensive and adaptable solution for EEG-based applications.

